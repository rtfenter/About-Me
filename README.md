# Portfolio Series  
Each series begins with its **main hub repo**, which organizes prototypes, diagrams, and essays.

---

## 1. Systems of Trust Series  

**Main Hub:**  
https://github.com/rtfenter/Systems-of-Trust-Series

Tools and models for **event governance, schema integrity, and truth preservation** in distributed systems.

**How to navigate**  
Start in the hub repo → open the prototypes inside it → explore linked live demos.

**Why it exists**  
Distributed systems fail quietly when meaning drifts.

**Why it matters**  
AI, automation, and multi-service scaling require consistent truth.

**Prototypes**  
- Event Quality Scanner — https://github.com/rtfenter/Event-Quality-Scanner  
- Truth Drift Map — https://github.com/rtfenter/Truth-Drift-Map  
- Event Consistency Checker — https://github.com/rtfenter/Event-Consistency-Checker

---

## 2. Loyalty Systems Series  

**Main Hub:**  
https://github.com/rtfenter/Loyalty-Systems-Series

Applied loyalty architecture for **FX, tiering, reconciliation, and value drift**.

**How to navigate**  
Start in the hub repo → open prototype repos → use linked live demos.

**Why it exists**  
Loyalty behaves like a distributed system, not a marketing feature.

**Why it matters**  
Value and meaning drift without strong contracts and reconciliation.

**Prototypes**  
- Loyalty Points Simulator — https://github.com/rtfenter/Loyalty-Points-Simulator  
- Loyalty Drift Dashboard — https://github.com/rtfenter/Loyalty-Drift-Dashboard  
- Loyalty Event Contract Validator — https://github.com/rtfenter/Loyalty-Event-Contract-Validator  

**Demo**  
- Live Demo — https://rtfenter.github.io/Loyalty-Event-Contract-Validator/

---

## 3. Applied Intelligence Systems Series  

**Main Hub:**  
https://github.com/rtfenter/Applied-Intelligence-Systems-Series

Tools exploring how **AI, agents, and intelligent systems interpret signals and drift over time**.

**How to navigate**  
Open the hub → explore prototypes → reference diagrams and planned expansions.

**Why it exists**  
Intelligent systems misalign for the same reasons distributed systems do — meaning, context, and ownership drift.

**Why it matters**  
Responsible AI needs architecture that protects interpretation, constraints, and authorship.

**Prototypes**  
- Agent Behavior Sandbox — https://github.com/rtfenter/Agent-Behavior-Sandbox

---

# Recursive Identity Architecture (RIA)

**Main Hub:**  
https://github.com/rtfenter/RIA-Research-Notes

RIA is my independent architecture for **holding contradiction, preserving coherence, and preventing drift** in complex systems — human or machine.

It underpins how I think about truth, architecture, and alignment across all three portfolio series.  
The hub repo includes the conceptual models, loops, explainers, and system notes that inform the prototypes across this GitHub.

---

# Connect

LinkedIn: https://www.linkedin.com/in/rtfenter/  
GitHub: https://github.com/rtfenter  
Medium: https://medium.com/@rtfenter
